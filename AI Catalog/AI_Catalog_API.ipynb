{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Catalog API Demo\n",
    "\n",
    "**Author:** Andrew Kruchko\n",
    "\n",
    "**Label:** AI Catalog\n",
    "\n",
    "**Scope**: The scope of this notebook is to provide instructions on how to create and share datasets in AI Catalog and use them to create projects and run predictions.\n",
    "\n",
    "**Requirements:** Python 3.7 or higher; DataRobot API version 2.21 or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DataRobot and read credencials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.Client(config_path='config_path.yaml')\n",
    "\n",
    "with open(\"config_path.yaml\", 'r') as stream:\n",
    "    creds = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_rest_call(url, req_func, payload=None):\n",
    "    \"\"\"\n",
    "    to run the API call\n",
    "    url: the API endpoint\n",
    "    req_func: a requests function e.g. requests.post\n",
    "    payload[optional]: a dictionary with parameters\n",
    "    \"\"\"\n",
    "    headers = {'Authorization': f\"Token {creds['token']}\",\n",
    "               'Content-Type': 'application/json;charset=UTF-8'}\n",
    "    return req_func(f\"{creds['base_url']}{url}\", headers=headers, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataset or a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a local file\n",
    "dataset = dr.Dataset.create_from_file(file_path=path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a file object\n",
    "with open(path_to_data, 'rb') as f:\n",
    "    dataset = dr.Dataset.create_from_file(filelike=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "df_lst = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a pandas data frame\n",
    "dataset = dr.Dataset.create_from_in_memory_data(data_frame=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a list of dictionaries representing rows of data\n",
    "dataset = dr.Dataset.create_from_in_memory_data(records=df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on csv data from a URL\n",
    "dataset = dr.Dataset.create_from_url(url='https://data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a DB\n",
    "# getting a dirver\n",
    "ms_sql_driver = [drv for drv in dr.DataDriver.list() if drv.class_name == 'com.microsoft.sqlserver.jdbc.SQLServerDriver'][-1]\n",
    "\n",
    "# creating a datastore\n",
    "datastore = dr.DataStore.create(data_store_type='jdbc', \n",
    "                                canonical_name='Demo DB', \n",
    "                                driver_id=ms_sql_driver.id, \n",
    "                                jdbc_url=creds['jdbc_url'])\n",
    "\n",
    "# creating a datasource based on a query\n",
    "query = \"select * from db.schema.table\"\n",
    "params = dr.DataSourceParameters(data_store_id=datastore.id, \n",
    "                                 query=query)\n",
    "\n",
    "datasource = dr.DataSource.create(data_source_type='jdbc', \n",
    "                                  canonical_name='datasource_query', \n",
    "                                  params=params)\n",
    "\n",
    "# creating a datasource based on a table\n",
    "params = dr.DataSourceParameters(data_store_id=datastore.id, \n",
    "                                 schema='schema',\n",
    "                                 table='table')\n",
    "\n",
    "datasource = dr.DataSource.create(data_source_type='jdbc', \n",
    "                                  canonical_name='datasource_table', \n",
    "                                  params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharing a dataset and a data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying a list of users to share with and their role\n",
    "users = ['user@domain.com']\n",
    "role = dr.enums.SHARING_ROLE.READ_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharing a dataset trough the API call\n",
    "data = {'data': [{'username': user, 'role': role} for user in users]}\n",
    "sharing_resp = dr_rest_call(f'/api/v2/datasets/{dataset.id}/accessControl', requests.patch, payload=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharing a data source using python client\n",
    "access_lst = [dr.SharingAccess(username=user, role=role) for user in users]\n",
    "datasource.share(access_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a project from a dataset\n",
    "dr.Project.create_from_dataset(dataset_id=dataset.id, \n",
    "                               project_name=dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a project from a data source\n",
    "dr.Project.create_from_data_source(data_source_id=datasource.id, \n",
    "                                   username=creds['db_user'], \n",
    "                                   password=creds['db_pass'], \n",
    "                                   project_name=datasource.canonical_name\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a dataset to run a batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying deployment and dataset id\n",
    "deployment_id = 'deployment id'\n",
    "dataset_id = 'dataset id'\n",
    "\n",
    "# preparing parameters to run a batch prediction job\n",
    "data = {'deploymentId': deployment_id,\n",
    "        'passthroughColumnsSet': 'all',\n",
    "        'intakeSettings': \n",
    "            {'type': 'dataset',\n",
    "             'datasetId': dataset_id},\n",
    "        'outputSettings':\n",
    "            {'type': 'localFile', \n",
    "            }\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running a batch prediction job\n",
    "batch_pred_resp = dr_rest_call('/api/v2/batchPredictions', requests.post, payload=data)\n",
    "\n",
    "# getting its id and the object based on it\n",
    "batch_pred_job_id = batch_pred_resp.json()['id']\n",
    "batch_pred_job = dr.BatchPredictionJob.get(batch_pred_job_id)\n",
    "\n",
    "# waiting for completion and writing the results\n",
    "batch_pred_job.wait_for_completion()\n",
    "with open('data/predictions.csv', 'wb') as f:\n",
    "    batch_pred_job.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
